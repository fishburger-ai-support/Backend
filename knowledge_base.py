import json
import os
import numpy as np
from sentence_transformers import SentenceTransformer

class KnowledgeBase:
    def __init__(self, kb_path='knowledge_base.json'):
        self.kb_path = kb_path
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.documents = []
        self.embeddings = []
        self.load_knowledge_base()
    
    def load_knowledge_base(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ JSON"""
        if os.path.exists(self.kb_path):
            with open(self.kb_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.documents = data.get('documents', [])
                
                if self.documents:
                    # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                    texts = [f"{doc['title']}\n{doc['content']}" for doc in self.documents]
                    self.embeddings = self.model.encode(texts)
                    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
    
    def search(self, query, top_k=3):
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not self.documents or not self.embeddings:
            return []
        
        # –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        query_emb = self.model.encode([query])
        
        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        scores = np.dot(self.embeddings, query_emb.T).flatten()
        
        # –ë–µ—Ä—ë–º top_k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        top_indices = np.argsort(scores)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            if scores[idx] > 0.3:  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞
                results.append({
                    'title': self.documents[idx]['title'],
                    'content': self.documents[idx]['content'],
                    'score': float(scores[idx])
                })
        
        return results
    
    def add_document(self, title, content):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        self.documents.append({'title': title, 'content': content})
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        texts = [f"{doc['title']}\n{doc['content']}" for doc in self.documents]
        self.embeddings = self.model.encode(texts)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(self.kb_path, 'w', encoding='utf-8') as f:
            json.dump({'documents': self.documents}, f, ensure_ascii=False, indent=2)